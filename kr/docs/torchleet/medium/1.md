# LSTM 구현하기
순서가 다소 뒤섞인거 같다구요? 저도 보자마자 그 생각 했습니다. 왜 LSTM이 RNN보다 먼저 나온 것일까요?
개인적인 추측이지만 확실하게 nn.LSTM을 사용해야 한다는 것 때문에 먼저 소개한 거 같습니다. 그냥 쌩으로 구현하면 복잡하니까요.

LSTM은 기존 RNN에서 소멸하는 기울기(vanishing gradient) 문제를 해결하기 위해 은닉층에 망각, 입력, 출력 게이트가 추가된 구조입니다.
nn.LSTM은 이 구성 요소들이 전부 있는 완전한 구조체이기 때문에, 그 자체로 한개의 모델입니다.

따라서 nn.LSTM 인스턴스에 텐서를 제공하면 결과 텐서와 역전파에 활용될 기울기 관련된게 tuple 형식으로 반환되니, 이를 제대로 unpacking 해 사용하시기를...

## 요구사항
- nn.LSTM을 활용했다.
- LSTM을 거친 결과를 적절하게 FC에 통과시켰다.
- 결과를 반환했다(어떻게 하는지는 자유입니다)

## 평가 기준
1. 재현 가능한 결과
    - [x] 코드 실행이 오류 없이 진행되었는가?
    - [x] Batch와 시퀀스의 임베딩간 혼동 없이 제대로 된 값에 적용했는가?
    - [x] 학습 이후 loss가 낮아야 한다.
2. 모델 구현
    - [x] LSTM 이후 FC의 구조를 따르고 있는가?
    - [x] 시퀀스를 활용해 결과를 내었는가? (실수할 수 있다)